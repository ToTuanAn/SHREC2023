/home/minhkhoi1026/miniconda3/envs/shrec2023/lib/python3.8/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
  rank_zero_warn(
[34m[1mwandb[39m[22m: logging graph, to disable use `wandb.watch(log_graph=False)`
/home/minhkhoi1026/miniconda3/envs/shrec2023/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:467: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.
  rank_zero_deprecation(
Using 16bit None Automatic Mixed Precision (AMP)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
You are using a CUDA device ('NVIDIA GeForce RTX 3050 Ti Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
['754687fa7f45b78e', 'a0664df1315a8aba', 'e27877b96a4abea2', 'bd7c3921a5829c5f', 'fc9dc8118f99c0de', 'ac0abb4cfebf48b4', '26808910ed0da6e0', 'fc9dc8118f99c0de', 'efc25a321f0359fe', 'e670143d0274784c', 'c8b07c3741bb4fc8', '13b02a5332f0ecd5', '505ea7c5b84466e2', '0534ec3a9103aa94', '25d3c279224e9090', '8b54089fee8d99a0', 'c50d24d1270b99ae', 'b34ab1000d8e4510', '958da55b0d75abfc', '70529c539a3eaf30', '9131efff3efffe99', '51c33db36e283711', '599966e85d6857ce', 'b1d44ce73b4b431b', '728ac3507f29b8b1', 'c074190530330c13', '3351535576ef36bd', '76d991719a89b736', 'd22a84b6f9f25ebe', '04b64385ccad4949', '2f61c298e0395353', '865728e99be03f56', '5110adc459f44b27', 'ac0abb4cfebf48b4', 'd0c9a887b794513a', '8eba7fddfa15f905', '04b64385ccad4949', '29e33756715c2125', '70529c539a3eaf30', 'dc38f0769707dc64', '5c7bbf629c64b765', 'fc9dc8118f99c0de', '29e33756715c2125', '999ef191bff8625d', '728ac3507f29b8b1', '76d991719a89b736', 'c50d24d1270b99ae', 'dbd7cff8e346e379']
['303ae000f3346db3', '83a6898b3cf63399', '5a47b8a4ad093e6c', 'fc2db06c4c42b0d2', '2accc11b14dde296', '0c27b52a88c33aae', 'fdfd2538c9269782', 'fe8ba017416507eb', 'cbef81f72fefce7a', '9946e34f45632be6', '6585855871402772', 'e406c931589df07b', '90ba6644ad322c47', '6f50fb3efc179160', '47d04be344220ba4', '7f9c5a47a8b18f00', 'cb6ef21b1c71cbbb', '6e92439ce227a932', '4c142b488845264b', 'a3f337038d154765', 'f0931310b6964a5e', '079c96c521c73ca9', 'b0334182d0c3faeb', '6bc2402ce628bbef', '60af2d4f86d5307c', 'e18ea7c595a3d53d', '1df3b0ad86562fde', 'e31ced3776eca0a7', '20b5e565c2f67b81', '13a49ab0aecbc76f', '834953da8335695b', '344e0698585e098a', 'fed99c4e5443d447', 'f72449d035d0ac79', '2846d0b05ed649cf', '01612cb400453597', 'bda1f6d4a4b5fe79', '36089dc42596904a', 'ab047afa481c3134', '2acea48879fd7fec', 'ae09892d3ad04b4b', '2268076b3b795a99', 'aa0598ae402d2833', '02bf2b708a98eb01', '2b72aa75a44e8847', '413505e6f4ddf95e', '0ae964801539411d', '18916433442bd760']
['754687fa7f45b78e', 'a0664df1315a8aba', 'e27877b96a4abea2', 'bd7c3921a5829c5f', 'fc9dc8118f99c0de', 'ac0abb4cfebf48b4', '26808910ed0da6e0', 'fc9dc8118f99c0de', 'efc25a321f0359fe', 'e670143d0274784c', 'c8b07c3741bb4fc8', '13b02a5332f0ecd5', '505ea7c5b84466e2', '0534ec3a9103aa94', '25d3c279224e9090', '8b54089fee8d99a0', 'c50d24d1270b99ae', 'b34ab1000d8e4510', '958da55b0d75abfc', '70529c539a3eaf30', '9131efff3efffe99', '51c33db36e283711', '599966e85d6857ce', 'b1d44ce73b4b431b', '728ac3507f29b8b1', 'c074190530330c13', '3351535576ef36bd', '76d991719a89b736', 'd22a84b6f9f25ebe', '04b64385ccad4949', '2f61c298e0395353', '865728e99be03f56', '5110adc459f44b27', 'ac0abb4cfebf48b4', 'd0c9a887b794513a', '8eba7fddfa15f905', '04b64385ccad4949', '29e33756715c2125', '70529c539a3eaf30', 'dc38f0769707dc64', '5c7bbf629c64b765', 'fc9dc8118f99c0de', '29e33756715c2125', '999ef191bff8625d', '728ac3507f29b8b1', '76d991719a89b736', 'c50d24d1270b99ae', 'dbd7cff8e346e379']
['303ae000f3346db3', '83a6898b3cf63399', '5a47b8a4ad093e6c', 'fc2db06c4c42b0d2', '2accc11b14dde296', '0c27b52a88c33aae', 'fdfd2538c9269782', 'fe8ba017416507eb', 'cbef81f72fefce7a', '9946e34f45632be6', '6585855871402772', 'e406c931589df07b', '90ba6644ad322c47', '6f50fb3efc179160', '47d04be344220ba4', '7f9c5a47a8b18f00', 'cb6ef21b1c71cbbb', '6e92439ce227a932', '4c142b488845264b', 'a3f337038d154765', 'f0931310b6964a5e', '079c96c521c73ca9', 'b0334182d0c3faeb', '6bc2402ce628bbef', '60af2d4f86d5307c', 'e18ea7c595a3d53d', '1df3b0ad86562fde', 'e31ced3776eca0a7', '20b5e565c2f67b81', '13a49ab0aecbc76f', '834953da8335695b', '344e0698585e098a', 'fed99c4e5443d447', 'f72449d035d0ac79', '2846d0b05ed649cf', '01612cb400453597', 'bda1f6d4a4b5fe79', '36089dc42596904a', 'ab047afa481c3134', '2acea48879fd7fec', 'ae09892d3ad04b4b', '2268076b3b795a99', 'aa0598ae402d2833', '02bf2b708a98eb01', '2b72aa75a44e8847', '413505e6f4ddf95e', '0ae964801539411d', '18916433442bd760']
Sanity Checking: 0it [00:00, ?it/s]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
  | Name           | Type          | Params
-------------------------------------------------
0 | pointnet       | PointNet      | 3.5 M
1 | lang_extractor | LangExtractor | 109 M
2 | pc_linear      | Linear        | 32.9 K
3 | lang_linear    | Linear        | 98.4 K
-------------------------------------------------
3.7 M     Trainable params
109 M     Non-trainable params
113 M     Total params
226.281   Total estimated model params size (MB)
/home/minhkhoi1026/miniconda3/envs/shrec2023/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.



Sanity Checking DataLoader 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23/24 [00:16<00:00,  1.44it/s]
/home/minhkhoi1026/miniconda3/envs/shrec2023/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.













Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š            | 104/120 [00:29<00:04,  3.47it/s, loss=1.08, v_num=fp75, train_loss_step=1.110]

Validation DataLoader 0:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                                  | 8/24 [00:00<00:01, 14.66it/s]















Epoch 1:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 96/120 [00:28<00:07,  3.32it/s, loss=1.05, v_num=fp75, train_loss_step=1.040, val_loss_step=0.450, val_loss_epoch=0.878, train_loss_epoch=1.040]


Validation DataLoader 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                              | 15/24 [00:01<00:01,  7.79it/s]














Epoch 2:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 103/120 [00:29<00:04,  3.47it/s, loss=1.03, v_num=fp75, train_loss_step=1.100, val_loss_step=0.863, val_loss_epoch=0.974, train_loss_epoch=1.040]


Validation DataLoader 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                              | 15/24 [00:01<00:01,  8.30it/s]














Epoch 3:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 103/120 [00:29<00:04,  3.46it/s, loss=1.02, v_num=fp75, train_loss_step=0.932, val_loss_step=0.630, val_loss_epoch=0.956, train_loss_epoch=1.050]


Validation DataLoader 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹               | 21/24 [00:02<00:00,  8.48it/s]













Epoch 4:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 96/120 [00:27<00:06,  3.49it/s, loss=1.03, v_num=fp75, train_loss_step=1.070, val_loss_step=1.030, val_loss_epoch=0.901, train_loss_epoch=1.020]


Validation DataLoader 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                   | 14/24 [00:01<00:01,  8.23it/s]













Epoch 5:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 104/120 [00:27<00:04,  3.77it/s, loss=1.01, v_num=fp75, train_loss_step=0.949, val_loss_step=0.594, val_loss_epoch=1.180, train_loss_epoch=1.030]

Validation DataLoader 0:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                                  | 8/24 [00:00<00:01,  8.65it/s]













Epoch 6:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 102/120 [00:27<00:04,  3.71it/s, loss=1.02, v_num=fp75, train_loss_step=0.831, val_loss_step=0.813, val_loss_epoch=2.170, train_loss_epoch=1.060]


Validation DataLoader 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹               | 21/24 [00:02<00:00,  8.36it/s]












Epoch 7:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 101/120 [00:26<00:05,  3.75it/s, loss=1.02, v_num=fp75, train_loss_step=0.948, val_loss_step=1.250, val_loss_epoch=1.050, train_loss_epoch=1.020]


Validation DataLoader 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 19/24 [00:02<00:00,  7.98it/s]












Epoch 8:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 98/120 [00:26<00:05,  3.67it/s, loss=1.03, v_num=fp75, train_loss_step=1.270, val_loss_step=0.943, val_loss_epoch=0.993, train_loss_epoch=1.020]

Validation DataLoader 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                   | 17/24 [00:01<00:00,  8.57it/s]















Epoch 9:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 106/120 [00:30<00:03,  3.50it/s, loss=0.969, v_num=fp75, train_loss_step=1.110, val_loss_step=0.988, val_loss_epoch=1.020, train_loss_epoch=1.000]
Validation DataLoader 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                       | 10/24 [00:00<00:01, 10.59it/s]












Epoch 10:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–       | 79/120 [00:21<00:10,  3.73it/s, loss=0.952, v_num=fp75, train_loss_step=0.779, val_loss_step=2.800, val_loss_epoch=1.070, train_loss_epoch=1.030]
/home/minhkhoi1026/miniconda3/envs/shrec2023/lib/python3.8/site-packages/pytorch_lightning/trainer/call.py:48: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...

Epoch 10:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ       | 81/120 [00:21<00:10,  3.75it/s, loss=0.947, v_num=fp75, train_loss_step=1.030, val_loss_step=2.800, val_loss_epoch=1.070, train_loss_epoch=1.030]